\chapter{并行化算法}
\label{chp:4}

算法并行化的第一步通常是设计一个符合待处理问题及处理器架构特点的并行方案，然后根据该方案确定相应的编程模型，最后分析并行程序的性能，有针对性地做具体的优化。
并行程序的性能优化和普通串行程序有许多共通之处。具体来说主要分为两个大类：针对内存使用的优化和针对for循环的改进。

由于日益增长的处理器速度和发展相对较缓的内存速度之间逐渐拉开了差距，内存通常成为程序蓄能的瓶颈。现代处理器通常采用分层内存体系，高带宽，低延迟（lower latency），低能耗的高速缓存对提升数据局部性(data locality)至关重要。针对缓存优化的方法有很多，例如对齐数据（data alignment）使得缓存的加载更有效率，依据缓存的大小处理相应的数据块（cache blocking），预读取（prefetching）提前将需要处理的数据加载到缓存中，或者通过流式存储技术（streaming store）将非时间相关（nontemporal）的计算结果"绕过"缓存直接写入主内存从而避免"污染"缓存其他数据等。和数据代码缓存一样，页表缓存（Translation Lookaside Buffer）也是影响性能的一个因素。页表缓存存储了一部分标签页表条目，用于改进从虚拟内存地址到物理地址的转译速度，对于特定问题，通过使用不同尺寸的页面大小，重构数据可以避免页表缓存中的热点。

针对for循环优化的一般技术包括循环展开（loop unrolling）,分块循环（loop tiling）, 循环互换（loop interchange），循环合并（loop fusion），循环偏移（loop skewing），循环剥离（loop peeling）等。这些改进很多时候也是为了更好地使用内存或者为进一步并行化做准备。
目前绝对意义上的串行程序在实际中已不多见，因为在编译过程中编译器会或多或少引入不同程度的并行化处理。然而由于编译器优化的前提是基于代码的正确性，串行程序的逻辑遵循一个绝对的代码执行顺序，因而其编写和调试难度远低于并行程序。并行程序的运行由于同时驱动不同的逻辑运算单元，容易出现数据的竞态条件（race condition）等导致最终结果不确定的因素。本章将着重描述几种针对本课题不同的并行方案，及其具体实现。

\section{并行性分析}
\label{sec:parallelism}
并行的目的就是在充分利用单机资源的基础上，将计算扩展到多个机器，在可接受的时间范围内处理规模更大，复杂度更高的问题。
在单个机器上，原则上我们需要发掘串行算法中的并行机会，将基本的并发性操作表述为任务（task）的形式提交给调度器（scheduler），再由调度器将其分发给不同的线程执行。在MIC这样的众核处理器上，足够的任务级并行度对于充分利用片上丰富的线程资源非常重要。由于时间的限制我们选择不重新实现一个新的调度算法，而是使用现有的工具，如OpenMP，Cilk+或者Threading Building Blocks(TBB)。
在多个节点上，我们采用消息传递模式如MPI来进行通信，目标是尽量降低通信量的同时，将计算和通信重叠起来，提高整体效率。

算法\ref{alg:bserror}描述了欧式期权对冲策略误差控制的串行算法。本章的核心目的就是论述基于该算法的并行化方案。
分析该算法可知蒙特卡洛模拟的结果依赖每次模拟求得的误差$error$，而求$error$的过程除了两项非随机量，其余均与$PX$相关。数组$PX$表示的是在离散时间点的期权价格，取值和一个随机布朗运动的各个状态相关联。该布朗运动可视作一个马尔科夫过程，前后两项相差一个符合高斯分布的随机数。由于其每两项之间存在数据依赖性，使得其并行度十分有限。因此问题的关键在于如何有效地打破这种数据之间的依赖性。本文所讨论的数据依赖性本质上源自于N个独立高斯分布的随机数组成的数组$NRV[N]$。对于一个给定的N和从$BM[N]$中选取的任何一段连续的子集$bm[n]$，如果可以并行地处理这些分段子集，我们就可以极大地提高计算效率，实现本节最初提出的目标。

计算某个子集的条件是已知其初始状态和该子集所对应$NRV[N]$中的子集。而该子集的初始状态可表示为其之前所有状态对应的正态分布随机数之和乘以一个常量。
因此有两种并行思路。第一种是将整个长度为N的数组分为连续的子集，按顺序每次所有的计算资源并发地参与计算其中一段子集，计算完成该段子集之后再计算紧邻的下一段。如此，计算下段子集的时候，它的初态就是上一段的终态加上一个随机数，而上段的终态是已知的。依据这种方案，基本的并行任务（task）是已知某段子集对应的所有的随机数，计算其中某个布朗运动状态，其对应的离散时间点的期权价格，以及最终的误差。

第二种思路是将我们之前所讨论的某段子集的处理直接作为基本的并行任务分配给线程计算。这样的话子集的初始状态是未知的，因为不能假设某个线程先后处理的是连续的子集。在这种情况下，需要根据之前生成的随机数来推断某段子集的初始状态。这就无法回避一个重要的问题，随机数发生器。

在目前的计算机应用里，几乎所有用到的随机数发生器都只能产生伪随机数。其原理通常是根据某种算法计算出一连串在实际应用中可认为相互独立的数。当该算法的结果空间足够大的时候，生成的伪随机数几乎没有可能重复，从而保证了算法的有效性。在该课题中，我们使用的是基于梅森旋转算法（Mersenne twister）的高斯分布随机数发生器，它有$2^{19937}-1$的非常长的周期。该随机数发生器的并行版本，在于生成不同的随机流（stream），不同的流使用不同的“种子（seed）”在不同的结果子空间中计算随机数，相互之间保持独立。

在我们的第一种并行思路中，我们只需要生成一条随机流，每次计算某段子集的时候空闲的线程利用随机数发生器生成下一个紧邻子集对应的随机数。所有随机数由全部线程共享，从而解除了数据的依赖性。
在第二种并行思路中，由于某段子集作为一个基本的任务分配给线程，不同线程间异步地对不同段子集进行操作，因此无法共享单条随机数组。在这种情况下，每个线程保有一条私有的随机数流，根据自己计算的进度按需生成相应的随机数。这种情况下对于数据依赖性的处理则在于随机数的“种子”。对于不同的流使用不同的种子固然是可以得到互相独立的随机数组。但如果使用相同的种子则会生成完全一样的随机数组。由于不同的线程虽然处理的子集不同，但都是针对同一个给定$N$的离散价格误差的计算，$N$个随机数理应一致。通过不同的随机流，不同的线程独立生成随机数，避免了相互之间的通信，从而解除了数据的依赖性。

根据以上提供的两种思路，我们利用Intel OpenMP实现了单机上的并行版本。由于该算法的最终目的是寻找一个最优的$N$以满足给定的可容忍概率。每一次迭代都需要$M$次蒙特卡洛模拟计算一个新的$N$值。在实际中，只有相对较大的$M$值才能得到令人信服的结果。因此对于把单机版本扩展到多个节点或机器，我们选择在$M$这个维度上并行。基本思路是基于Master-Slave模型由一个主机（boss）收集由工作机（worker）发送过来的结果，分析整理之后决定下一次计算的$N$\footnote{关于$N$的最优化搜索具体讨论见\ref{}}值并发送给工作机。工作机在等待指令的同时自行选取一个更小的$N$值继续计算。接受到主机指令之后假如自行计算的$N$值和主机指令相同，则继续完成。否则舍弃计算结果重新开始一个新的$N$值的计算。为了更好地重叠计算和通信，我们采用非阻塞通信模式，如此，工作机可以充分发挥计算效能，避免空隙或等待。具体的实现细节参见\ref{}。

\section{单机并行算法}
\label{sec:monoparallel}
根据上节\ref{sec:parallelism}的分析，我们在这里给出两种单机并行思路的具体实现细节。在实际中，我们采用Intel MKL（Math Kernel Library）提供的高斯分布随机数发生器。该发生器基于梅森旋转算法。每次可生成单个或多个随机数。
\subsection{方案一}
该方案将整段N分为相邻连续的子集，分段对每一段子集进行并行处理。
\begin{algorithm}
  \caption{基于多线程（multithreading）和矢量化（vectorization）的单机并行算法(单次蒙特卡洛模拟)}
  \label{alg:omp1}
  \begin{algorithmic}[1]
    \Require $X_0, \sigma, K, T, \epsilon, Prob, N_0, M$ (参见算法\ref{alg:bserror})
    \Require $N_{cache}$ \Comment{依序并行处理的子集大小}
    \Procedure{$mono_1$}{$N_{cache}$}
    \State $error \gets 0$
    \State $NRV[N_{cache}] \gets vdRngGaussian(N_{cache})$ \Comment{一次生成$N_{cache}$个符合高斯分布的随机数}
    \State $BM[N_{cache}]$
    \State $PX[N_{cache}]$
    \State $PX[0] \gets 0$
    \State $\delta t \gets T/N$
    \State $BM[0] \gets \sqrt{\delta t} \times NRV[0]$
    \For{$k=1:(int)N/N_{cache}$}
    \State \textbf{Start parallel region}
    \For{$i=1:N_{cache}$}
    \State $BM[i] = BM[0] + reduce\_add(NRV[1:i])$ \Comment{SIMD reduction操作}
    \State $PX[i+1] = X_0 \times \exp(-0.5 \sigma^2 \times (kN_{cache}+i+1) \times \delta t + \sigma \times BM[i])$
    \EndFor
    \State \textbf{End parallel region}
    $PX[1] = X_0 \times \exp(-0.5 \sigma^2 \times (kN_{cache}+1) \times \delta t + \sigma \times BM[i])$
    \State \textbf{Start parallel region reduction(+:error) nowait}
    \For{$i=0:N_{cache}$} 
    \State $j \gets kN_{cache}+1$
    \State $T_j \gets {j \times T}/{N}$
    \State $Upper = (\log(PX[i]/K)+0.5\times \sigma^2 \times (T-T_j))/(\sigma \times \sqrt{T-T_j})$
    \State $error \gets error - \frac{1}{\sqrt{2\pi}}\times (PX[i+1]-PX[i])\times \int_{-\infty}^{Upper1}e^{-\frac{t^2}{2}}dt$
    \EndFor
    \State \textbf{End parallel region}
    \State $NRV[N_{cache}] \gets vdRngGaussian(N_{cache})$ 
    \State $BM[0] = BM[N_{cache}-1] + \sqrt{\delta t}\times NRV[0]$
    \State $PX[0] \gets PX[Ncache]$
    \EndFor
    
    \EndProcedure
  \end{algorithmic}
\end{algorithm}











$N$值的选择

\section{N的最优化搜索}
\label{sec:researchN}
在获得一个可接受的$N$值后，我们可以继续寻找满足条件的更小的$N$值，一般初始的$N$值取的较大，所以这种最优化的寻找可以通过一个二分法的搜寻算法来实现。
\begin{algorithm}
	\caption{最优$N$值的搜索算法}
	\label{alg:searchN}
	\begin{algorithmic}[1]
		\State 参数 $M0$ \Comment{蒙特卡洛模拟的次数，$M0$越大模拟结果可信度越高}
		\Procedure{NBSECT}{$N0$, $\lambda$} \Comment{$N0$是初始化抽样次数，$\lambda$是最优解的置信区间}
		\State $nL \gets 1$ \Comment{设置$n$值的初始下界} 
		\State $nU \gets N0$ \Comment{设置$n$值的初始上界}
		\State $n \gets 0.5\cdot (nL + nU)$
		\While {$|nU - nL| > \lambda$} 
		\If {$BSERROR(M0,n) < n$} \Comment{缩小搜索范围}
		\State $nU \gets n$
		\State $n \gets 0.5\cdot(nL + nU)$ 		
		\Else  \Comment{扩大搜索范围}
		\State $nL \gets n$
		\State $n \gets 0.5\cdot(nL + nU)$ 		
		\EndIf
		\EndWhile
		\State return $n, nU, nL$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
在算法 \ref{alg:searchN} 中我们设置的收敛条件为$|nU - nL| \le \lambda$ 这是因为蒙特卡洛模拟本身具有一定的随机性。在$N$的收敛过程中会出现波动，导致无法
收敛到一个单一的值上，在$BSERROR$中给定了置信概率$Prob$的情况下，我们很自然地就能利用置信区间这一概念来表述我们取到的最优值$N$。在实际应用中，
$N$的初始值通常需要取得很大，然后通过二分法来逐步缩小范围取得最优值。此外蒙特卡洛模拟得次数$M$也需要取一个很大的值来保证其精确性。如果$N$和$M$的取值
都较大，就会极大地增加计算时间和内存空间需求。这时串行程序在普通的计算机上就难以满足问题的需求，我们将需要转而开发并行程序并使其运行在超级计算机上。
